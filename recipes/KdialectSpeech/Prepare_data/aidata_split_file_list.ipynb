{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "sys.path.append('../kdialectspeech')\n",
    "from time_convert import time_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "log_file = sys.argv[0] + \"_\" + datetime.now().strftime('%Y-%m-%d_%H:%M:%S') + \".log\"\n",
    "logging.basicConfig(filename=log_file, level = logging.INFO, datefmt = '%Y-%m-%d %H%M%S'\n",
    "                   ,format = '%(asctime)s | %(levelname)s | %(message)s')\n",
    "streamHandler = logging.StreamHandler()\n",
    "logger.addHandler(streamHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_of(base_dir, province):\n",
    "    province_code = province\n",
    "\n",
    "    if province_code == \"gw\":\n",
    "        data_dir = os.path.join(base_dir, \"139-1.중·노년층 한국어 방언 데이터 (강원도, 경상도)/06.품질검증/1.Dataset/1.원천데이터/01. 강원도\")\n",
    "        label_dir = os.path.join(base_dir, \"139-1.중·노년층 한국어 방언 데이터 (강원도, 경상도)/06.품질검증/1.Dataset/2.라벨링데이터/01. 강원도\")\n",
    "    elif province_code == \"gs\":\n",
    "        data_dir = os.path.join(base_dir, \"139-1.중·노년층 한국어 방언 데이터 (강원도, 경상도)/06.품질검증/1.Dataset/1.원천데이터/02. 경상도\")\n",
    "        label_dir = os.path.join(base_dir, \"139-1.중·노년층 한국어 방언 데이터 (강원도, 경상도)/06.품질검증/1.Dataset/2.라벨링데이터/02. 경상도\")\n",
    "    elif province_code == \"cc\":\n",
    "        data_dir = os.path.join(base_dir, \"139-2.중·노년층 한국어 방언 데이터 (충청도, 전라도, 제주도)/06.품질검증/1.Dataset/1.원천데이터/01. 충청도\")\n",
    "        label_dir = os.path.join(base_dir, \"139-2.중·노년층 한국어 방언 데이터 (충청도, 전라도, 제주도)/06.품질검증/1.Dataset/2.라벨링데이터/01. 충청도\")\n",
    "    elif province_code == \"jl\":\n",
    "        data_dir = os.path.join(base_dir, \"139-2.중·노년층 한국어 방언 데이터 (충청도, 전라도, 제주도)/06.품질검증/1.Dataset/1.원천데이터/02. 전라도\")\n",
    "        label_dir = os.path.join(base_dir, \"139-2.중·노년층 한국어 방언 데이터 (충청도, 전라도, 제주도)/06.품질검증/1.Dataset/2.라벨링데이터/02. 전라도\")\n",
    "    elif province_code == \"jj\":\n",
    "        data_dir = os.path.join(base_dir, \"139-2.중·노년층 한국어 방언 데이터 (충청도, 전라도, 제주도)/06.품질검증/1.Dataset/1.원천데이터/03. 제주도\")\n",
    "        label_dir = os.path.join(base_dir, \"139-2.중·노년층 한국어 방언 데이터 (충청도, 전라도, 제주도)/06.품질검증/1.Dataset/2.라벨링데이터/03. 제주도\")\n",
    "    else:\n",
    "        err_msg = (\n",
    "            \"지역 코드를 gw, gs, cc, jl, jj 중 하나를 입력해야 합니다. (gw:강원도, gs:경상도, cc:충청도, jl:전라도, jj:제주도)\"\n",
    "        )\n",
    "        raise OSError(err_msg)\n",
    "    \n",
    "    return data_dir, label_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list_of(base_dir, province):\n",
    "    data_dir, label_dir = dir_of(base_dir, province)\n",
    "    data_file_list = (glob.glob(os.path.join(data_dir, '*/*.' + \"wav\")))\n",
    "    json_file_list = (glob.glob(os.path.join(label_dir, '*/*.' + \"json\")))\n",
    "\n",
    "    return data_file_list, json_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manifest_of(json_file):\n",
    "    data_id = Path(json_file).stem # 확장자 제거\n",
    "    data_file = str(json_file).replace(\"2.라벨링데이터\", \"1.원천데이터\",).replace(\".json\", \".wav\")\n",
    "    # print(f'data_file : {data_file}')\n",
    "    \n",
    "    with open(json_file, encoding=\"UTF-8\" ) as j_f :\n",
    "        json_data = json.load(j_f)\n",
    "\n",
    "    try:\n",
    "        recordDuration = json_data[\"audio\"][\"recordDuration\"]\n",
    "    except:\n",
    "        logger.info(f\"no recordDuration, file_name : {json_file}\")\n",
    "        recordDuration = 0.0\n",
    "\n",
    "    try:\n",
    "        dialect = json_data[\"transcription\"][\"dialect\"]\n",
    "    except:\n",
    "        logger.info(f\"no_dialect, file_name : {json_file}\")\n",
    "        dialect = \"no_dialect\"\n",
    "    \n",
    "    manifest_line = [data_id, data_file, str(json_file), recordDuration, dialect]\n",
    "    return manifest_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manifest_of_list(json_file_list):\n",
    "    manifest_lines = []\n",
    "    for json_file in json_file_list:\n",
    "        manifest_line = manifest_of(json_file)\n",
    "        manifest_lines.append(manifest_line)\n",
    "\n",
    "    return manifest_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"/data/aidata\")\n",
    "# province_code_list = [\"jj\", \"jl\", \"gw\", \"gs\", \"cc\"]\n",
    "province_code = \"jj\"\n",
    "\n",
    "_, json_file_list = file_list_of(base_dir, province_code)\n",
    "manifest_list = manifest_of_list(json_file_list)\n",
    "manifest_df  = pd.DataFrame(data=manifest_list, columns=[\"id\", \"wav\", \"json\", \"recordDuration\", \"dialect\"])\n",
    "\n",
    "# total_speechStartTime = manifest_df[\"speechStartTime\"].sum()/3600 # sec of an hour\n",
    "# logger.info(f\"total speech StartTime of {province} : {total_speechStartTime}\")\n",
    "\n",
    "# total_recordDuration = manifest_df[\"recordDuration\"].sum()/3600 # sec of an hour\n",
    "# logger.info(f\"total record duration of {province} : {total_recordDuration}\")\n",
    "\n",
    "manifest_file = Path(province_code + \"_json.csv\")\n",
    "manifest_df.to_csv(manifest_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest_df = pd.read_csv(\"jj_json.csv\")\n",
    "len(manifest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split total csv into train, valid, test - 8:1:1\n",
    "manifest_train_df, manifest_valid_df, manifest_test_df = np.split(\n",
    "    manifest_df.sample(frac=1, random_state=7774), \n",
    "    [int(.8*len(manifest_df)), int(.9*len(manifest_df))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45332"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manifest_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manifest_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manifest_test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
