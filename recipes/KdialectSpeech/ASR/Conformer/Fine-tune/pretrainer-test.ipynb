{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import speechbrain as sb\n",
    "from torch.utils.data import DataLoader\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from speechbrain.utils.parameter_transfer import Pretrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_file = 'hparams/conformer_medium.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hparams_file) as fin:\n",
    "    hparams = load_hyperpyyaml(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = hparams['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training procedure\n",
    "class ASR(sb.core.Brain):\n",
    "    def compute_forward(self, batch, stage):\n",
    "        \"\"\"Forward computations from the waveform batches\n",
    "        to the output probabilities.\"\"\"\n",
    "        # print(f'compute_forward ----- 1')\n",
    "        # print(f'type of batch : {batch}')\n",
    "        batch = batch.to(self.device)\n",
    "        # print(f'compute_forward ----- 2')\n",
    "        wavs, wav_lens = batch.sig\n",
    "        # print(f'wavs, wav_lens : {wavs}, {wav_lens}')\n",
    "        # print(f'compute_forward ----- 3')\n",
    "        # print(f'wavs : {wavs}')\n",
    "        # print(f'wav_lens : {wav_lens}')\n",
    "        tokens_bos, _ = batch.tokens_bos\n",
    "\n",
    "        # Add augmentation if specified\n",
    "        ### kdialectspeech, ksponspeech, librispeech 에서는 사용안함, template 예제에서 사용\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            if hasattr(self.modules, \"env_corrupt\"):\n",
    "                wavs_noise = self.modules.env_corrupt(wavs, wav_lens)\n",
    "                wavs = torch.cat([wavs, wavs_noise], dim=0)\n",
    "                wav_lens = torch.cat([wav_lens, wav_lens])\n",
    "                tokens_bos = torch.cat([tokens_bos, tokens_bos], dim=0)\n",
    "\n",
    "        # compute features\n",
    "        feats = self.hparams.compute_features(wavs)\n",
    "        current_epoch = self.hparams.epoch_counter.current\n",
    "        feats = self.modules.normalize(feats, wav_lens, epoch=current_epoch)\n",
    "\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            if hasattr(self.hparams, \"augmentation\"):\n",
    "                feats = self.hparams.augmentation(feats)\n",
    "\n",
    "        # forward modules\n",
    "        src = self.modules.CNN(feats)\n",
    "        # print(f'tokens_bos : {tokens_bos}')\n",
    "        # print(f'pad_idx : {self.hparams.pad_index}')\n",
    "        enc_out, pred = self.modules.Transformer( # pred : decoder out\n",
    "            src, tokens_bos, wav_lens, pad_idx=self.hparams.pad_index\n",
    "        )\n",
    "\n",
    "        # output layer for ctc log-probabilities\n",
    "        logits = self.modules.ctc_lin(enc_out)\n",
    "        p_ctc = self.hparams.log_softmax(logits)\n",
    "\n",
    "        # output layer for seq2seq log-probabilities\n",
    "        pred = self.modules.seq_lin(pred)\n",
    "        p_seq = self.hparams.log_softmax(pred)\n",
    "\n",
    "        # print(f'enc_out size : {enc_out.size()}')\n",
    "        # Compute outputs\n",
    "        hyps = None\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            hyps = None\n",
    "        elif stage == sb.Stage.VALID:\n",
    "            hyps = None\n",
    "            current_epoch = self.hparams.epoch_counter.current\n",
    "            if current_epoch % self.hparams.valid_search_interval == 0:\n",
    "                # for the sake of efficiency, we only perform beamsearch with\n",
    "                # limited capacity and no LM to give user some idea of\n",
    "                # how the AM is doing\n",
    "                ####\n",
    "                #### 시간이 많이 걸리는 부분 : 아래 valid_search\n",
    "                ####\n",
    "                # print(f' valid enc_out size : {enc_out.size()}')\n",
    "                # print(f' valid wav_lens : {wav_lens}')\n",
    "                hyps, _ = self.hparams.valid_search(enc_out.detach(), wav_lens)\n",
    "                # print(f' valid hyps : {hyps}')\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            # print(f'compute_forward ----- 4')\n",
    "            # print(f' test enc_out size : {enc_out.size()}')\n",
    "            hyps, _ = self.hparams.test_search(enc_out.detach(), wav_lens) # test_search와 valid_search의 차이는 LM 사용 여부\n",
    "            # print(f' test hyps : {hyps}')\n",
    "            # print(f'compute_forward ----- 5')\n",
    "        # print(f'compute_forward ------------------------------------')\n",
    "        # print(f'compute_forward p_ctc ----- : {p_ctc}')\n",
    "        # print(f'compute_forward p_seq ----- : {p_seq}')\n",
    "        # print(f'compute_forward wav_lens ----- : {wav_lens}')\n",
    "        # print(f'compute_forward hyps ----- : {hyps}')\n",
    "        return p_ctc, p_seq, wav_lens, hyps\n",
    "\n",
    "    def compute_objectives(self, predictions, batch, stage):\n",
    "        \"\"\"Computes the loss (CTC+NLL) given predictions and targets.\"\"\"\n",
    "        \n",
    "        # print(f'compute_objectives ----- 1')\n",
    "        (p_ctc, p_seq, wav_lens, hyps,) = predictions\n",
    "\n",
    "        ids = batch.id\n",
    "        # print(f'compute_objectives ids : {ids}')\n",
    "        tokens_eos, tokens_eos_lens = batch.tokens_eos\n",
    "        tokens, tokens_lens = batch.tokens\n",
    "        \n",
    "        # logger.info(f'compute_objectives tokens.size ----- : {tokens.size()}') # npark\n",
    "\n",
    "        if hasattr(self.modules, \"env_corrupt\") and stage == sb.Stage.TRAIN:\n",
    "            tokens_eos = torch.cat([tokens_eos, tokens_eos], dim=0)\n",
    "            tokens_eos_lens = torch.cat(\n",
    "                [tokens_eos_lens, tokens_eos_lens], dim=0\n",
    "            )\n",
    "            tokens = torch.cat([tokens, tokens], dim=0)\n",
    "            tokens_lens = torch.cat([tokens_lens, tokens_lens], dim=0)\n",
    "\n",
    "\n",
    "        # print(f' compute_objectives tokens_eos : {tokens_eos}')\n",
    "        # print(f' compute_objectives p_seq : {p_seq}')\n",
    "        loss_seq = self.hparams.seq_cost(\n",
    "            p_seq, tokens_eos, length=tokens_eos_lens\n",
    "        )\n",
    "        loss_ctc = self.hparams.ctc_cost(p_ctc, tokens, wav_lens, tokens_lens)\n",
    "        loss = (\n",
    "            self.hparams.ctc_weight * loss_ctc\n",
    "            + (1 - self.hparams.ctc_weight) * loss_seq\n",
    "        )\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            # print(f'compute_objectives stage is not train -------------')\n",
    "            current_epoch = self.hparams.epoch_counter.current\n",
    "            valid_search_interval = self.hparams.valid_search_interval\n",
    "            if current_epoch % valid_search_interval == 0 or (\n",
    "                stage == sb.Stage.TEST\n",
    "            ):\n",
    "                # Decode token terms to words\n",
    "                predicted_words = [\n",
    "                    tokenizer.decode_ids(utt_seq).split(\" \") for utt_seq in hyps\n",
    "                ]\n",
    "                target_words = [wrd.split(\" \") for wrd in batch.wrd]\n",
    "\n",
    "                ### predicted_swords = get_swords(hyps, wrd) -> space normalized words\n",
    "\n",
    "                predicted_chars = [\n",
    "                    list(\"\".join(utt_seq)) for utt_seq in predicted_words\n",
    "                ]\n",
    "                target_chars = [list(\"\".join(wrd.split())) for wrd in batch.wrd]\n",
    "                self.wer_metric.append(ids, predicted_words, target_words)\n",
    "                # self.swer_metric.append(ids, predicted_swords, target_words)\n",
    "                self.cer_metric.append(ids, predicted_chars, target_chars)\n",
    "\n",
    "            # compute the accuracy of the one-step-forward prediction\n",
    "            self.acc_metric.append(p_seq, tokens_eos, tokens_eos_lens)\n",
    "            \n",
    "        # logger.info(f'compute_objectives loss ----- : {loss}') # npark\n",
    "        return loss\n",
    "\n",
    "    def fit_batch(self, batch):\n",
    "        \"\"\"Train the parameters given a single batch in input\"\"\"\n",
    "        # check if we need to switch optimizer\n",
    "        # if so change the optimizer from Adam to SGD\n",
    "        \n",
    "        # print(f'train length of batch : {len(batch)}')\n",
    "        self.check_and_reset_optimizer()\n",
    "\n",
    "        predictions = self.compute_forward(batch, sb.Stage.TRAIN)\n",
    "        loss = self.compute_objectives(predictions, batch, sb.Stage.TRAIN)\n",
    "\n",
    "        # normalize the loss by gradient_accumulation step\n",
    "        (loss / self.hparams.gradient_accumulation).backward()\n",
    "\n",
    "        if self.step % self.hparams.gradient_accumulation == 0:\n",
    "            # gradient clipping & early stop if loss is not fini\n",
    "            self.check_gradients(loss)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # anneal lr every update\n",
    "            self.hparams.noam_annealing(self.optimizer)\n",
    "\n",
    "            if isinstance(\n",
    "                self.hparams.train_logger,\n",
    "                sb.utils.train_logger.TensorboardLogger,\n",
    "            ):\n",
    "                self.hparams.train_logger.log_stats(\n",
    "                    stats_meta={\"step\": self.step}, train_stats={\"loss\": loss},\n",
    "                )\n",
    "\n",
    "        return loss.detach()\n",
    "\n",
    "    def evaluate_batch(self, batch, stage):\n",
    "        \"\"\"Computations needed for validation/test batches\"\"\"\n",
    "        # print(f'stage : {stage}')\n",
    "        # print(f'length of batch : {len(batch)}')\n",
    "        # print(f'batch.id type -------- : {type(batch.id)}')\n",
    "        # print(f'batch.id -------- : {batch.id}')\n",
    "        # print(f'batch sig type : {type(batch.sig)}')\n",
    "        # print(f'batch sig : {batch.sig[0]}')\n",
    "        # print(f'batch sig size : {batch.sig[0].size()}')\n",
    "        \n",
    "        \n",
    "        # for k, v in batch.sig:\n",
    "        #     print(k)\n",
    "        #     print(v)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # print('########## compute_forward #########')\n",
    "            predictions = self.compute_forward(batch, stage=stage)\n",
    "            # print(f'########## compute_objectives ######### stage : {stage}')\n",
    "            loss = self.compute_objectives(predictions, batch, stage=stage)\n",
    "            # print('########## eval end #########')\n",
    "        return loss.detach()\n",
    "\n",
    "    def on_stage_start(self, stage, epoch):\n",
    "        \"\"\"Gets called at the beginning of each epoch\"\"\"\n",
    "        if stage != sb.Stage.TRAIN:\n",
    "            self.acc_metric = self.hparams.acc_computer()\n",
    "            self.wer_metric = self.hparams.error_rate_computer()\n",
    "            # self.swer_metric = self.hparams.error_rate_computer()\n",
    "            self.cer_metric = self.hparams.error_rate_computer()\n",
    "\n",
    "    def on_stage_end(self, stage, stage_loss, epoch):\n",
    "        \"\"\"Gets called at the end of a epoch.\"\"\"\n",
    "        # Compute/store important stats\n",
    "        stage_stats = {\"loss\": stage_loss}\n",
    "        if stage == sb.Stage.TRAIN:\n",
    "            self.train_stats = stage_stats\n",
    "        else:\n",
    "            stage_stats[\"ACC\"] = self.acc_metric.summarize()\n",
    "            current_epoch = self.hparams.epoch_counter.current\n",
    "            valid_search_interval = self.hparams.valid_search_interval\n",
    "            if (\n",
    "                current_epoch % valid_search_interval == 0\n",
    "                or stage == sb.Stage.TEST\n",
    "            ):\n",
    "                stage_stats[\"WER\"] = self.wer_metric.summarize(\"error_rate\")\n",
    "                # stage_stats[\"sWER\"] = self.swer_metric.summarize(\"error_rate\")\n",
    "                stage_stats[\"CER\"] = self.cer_metric.summarize(\"error_rate\")\n",
    "\n",
    "        # log stats and save checkpoint at end-of-epoch\n",
    "        if stage == sb.Stage.VALID and sb.utils.distributed.if_main_process():\n",
    "\n",
    "            # report different epoch stages according current stage\n",
    "            current_epoch = self.hparams.epoch_counter.current\n",
    "            if current_epoch <= self.hparams.stage_one_epochs:\n",
    "                lr = self.hparams.noam_annealing.current_lr\n",
    "                steps = self.hparams.noam_annealing.n_steps\n",
    "            else:\n",
    "                lr = self.hparams.lr_sgd\n",
    "                steps = -1\n",
    "\n",
    "            epoch_stats = {\"epoch\": epoch, \"lr\": lr, \"steps\": steps}\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta=epoch_stats,\n",
    "                train_stats=self.train_stats,\n",
    "                valid_stats=stage_stats,\n",
    "            )\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"ACC\": stage_stats[\"ACC\"], \"epoch\": epoch},\n",
    "                max_keys=[\"ACC\"],\n",
    "                num_to_keep=5,\n",
    "            )\n",
    "\n",
    "        elif stage == sb.Stage.TEST:\n",
    "            self.hparams.train_logger.log_stats(\n",
    "                stats_meta={\"Epoch loaded\": self.hparams.epoch_counter.current},\n",
    "                test_stats=stage_stats,\n",
    "            )\n",
    "            with open(self.hparams.wer_file, \"w\") as w:\n",
    "                # self.swer_metric.write_stats(w)\n",
    "                self.wer_metric.write_stats(w)\n",
    "                self.cer_metric.write_stats(w)\n",
    "\n",
    "            # save the averaged checkpoint at the end of the evaluation stage\n",
    "            # delete the rest of the intermediate checkpoints\n",
    "            # ACC is set to 1.1 so checkpointer\n",
    "            # only keeps the averaged checkpoint\n",
    "            self.checkpointer.save_and_keep_only(\n",
    "                meta={\"ACC\": 1.1, \"epoch\": epoch},\n",
    "                max_keys=[\"ACC\"],\n",
    "                num_to_keep=1,\n",
    "            )\n",
    "\n",
    "    def check_and_reset_optimizer(self):\n",
    "        \"\"\"reset the optimizer if training enters stage 2\"\"\"\n",
    "        current_epoch = self.hparams.epoch_counter.current\n",
    "        if not hasattr(self, \"switched\"):\n",
    "            self.switched = False\n",
    "            if isinstance(self.optimizer, torch.optim.SGD):\n",
    "                self.switched = True\n",
    "\n",
    "        if self.switched is True:\n",
    "            return\n",
    "\n",
    "        if current_epoch > self.hparams.stage_one_epochs:\n",
    "            self.optimizer = self.hparams.SGD(self.modules.parameters())\n",
    "\n",
    "            if self.checkpointer is not None:\n",
    "                self.checkpointer.add_recoverable(\"optimizer\", self.optimizer)\n",
    "\n",
    "            self.switched = True\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        \"\"\"Initialize the right optimizer on the training start\"\"\"\n",
    "        super().on_fit_start()\n",
    "\n",
    "        # if the model is resumed from stage two, reinitialize the optimizer\n",
    "        current_epoch = self.hparams.epoch_counter.current\n",
    "        current_optimizer = self.optimizer\n",
    "        if current_epoch > self.hparams.stage_one_epochs:\n",
    "            del self.optimizer\n",
    "            self.optimizer = self.hparams.SGD(self.modules.parameters())\n",
    "\n",
    "            # Load latest checkpoint to resume training if interrupted\n",
    "            if self.checkpointer is not None:\n",
    "\n",
    "                # do not reload the weights if training is interrupted\n",
    "                # right before stage 2\n",
    "                group = current_optimizer.param_groups[0]\n",
    "                if \"momentum\" not in group:\n",
    "                    return\n",
    "\n",
    "                self.checkpointer.recover_if_possible(\n",
    "                    device=torch.device(self.device)\n",
    "                )\n",
    "\n",
    "    def on_evaluate_start(self, max_key=None, min_key=None):\n",
    "        \"\"\"perform checkpoint averge if needed\"\"\"\n",
    "        super().on_evaluate_start()\n",
    "\n",
    "        ckpts = self.checkpointer.find_checkpoints(\n",
    "            max_key=max_key, min_key=min_key\n",
    "        )\n",
    "        ckpt = sb.utils.checkpoints.average_checkpoints(\n",
    "            ckpts, recoverable_name=\"model\", device=self.device\n",
    "        )\n",
    "\n",
    "        self.hparams.model.load_state_dict(ckpt, strict=True)\n",
    "        self.hparams.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer initialization\n",
    "asr_brain = ASR(\n",
    "    modules=hparams[\"modules\"],\n",
    "    opt_class=hparams[\"Adam\"],\n",
    "    hparams=hparams,\n",
    "    # run_opts=run_opts,\n",
    "    checkpointer=hparams[\"checkpointer\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_brain.tokenizer = hparams[\"tokenizer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = '../Inference/pretrained-model-src/kspon/asr.ckpt'\n",
    "pretrain = Pretrainer(collect_in='model_local', loadables={'model': asr_brain}, paths={'model': pretrained_model})\n",
    "# pretrain = Pretrainer(collect_in='model_local', loadables={'model': model}, paths={'model': pretrained_model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': PosixPath('model_local/model.ckpt')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain.collect_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_colleted name : model\n",
      "load_colleted PARAMFILE_EXT : .ckpt\n",
      "load_colleted paramfiles[name] : model_local/model.ckpt\n",
      "Pretrainer _call_load_hooks name : model\n",
      "DEFAULT_TRANSFER_HOOKS ----- : {<class 'torch.nn.modules.module.Module'>: <function torch_parameter_transfer at 0x7f26850f9940>, <class 'sentencepiece.SentencePieceProcessor'>: <function _load_spm at 0x7f26850f99d0>, <class 'speechbrain.processing.features.InputNormalization'>: <function InputNormalization._load at 0x7f264996f670>}\n",
      "DEFAULT_LOAD_HOOKS ----- : {<class 'torch.nn.modules.module.Module'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.optimizer.Optimizer'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.lr_scheduler._LRScheduler'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.cuda.amp.grad_scaler.GradScaler'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.lr_scheduler.CyclicLR'>: <function _cycliclrloader at 0x7f24ebf8ee50>, <class 'speechbrain.dataio.encoder.CategoricalEncoder'>: <function CategoricalEncoder.load_if_possible at 0x7f2685103160>, <class 'speechbrain.dataio.dataloader.SaveableDataLoader'>: <function SaveableDataLoader._speechbrain_load at 0x7f265abc1dc0>, <class 'speechbrain.dataio.dataloader.LoopedLoader'>: <function LoopedLoader.load at 0x7f265ab70160>, <class 'speechbrain.utils.epoch_loop.EpochCounter'>: <function EpochCounter._recover at 0x7f265a7f68b0>, <class 'speechbrain.core.Brain'>: <function Brain._recover at 0x7f2649ac1b80>, <class 'speechbrain.nnet.schedulers.NewBobScheduler'>: <function NewBobScheduler.load at 0x7f2649a59ca0>, <class 'speechbrain.nnet.schedulers.LinearWarmupScheduler'>: <function LinearWarmupScheduler.load at 0x7f2649a690d0>, <class 'speechbrain.nnet.schedulers.NoamScheduler'>: <function NoamScheduler.load at 0x7f2649a695e0>, <class 'speechbrain.nnet.schedulers.CyclicCosineScheduler'>: <function CyclicCosineScheduler.load at 0x7f2649a698b0>, <class 'speechbrain.nnet.schedulers.ReduceLROnPlateau'>: <function ReduceLROnPlateau.load at 0x7f2649a69af0>, <class 'speechbrain.nnet.schedulers.CyclicLRScheduler'>: <function CyclicLRScheduler.load at 0x7f2649a69ee0>, <class 'speechbrain.nnet.schedulers.IntervalScheduler'>: <function IntervalScheduler.load at 0x7f2649a6b280>, <class 'speechbrain.nnet.schedulers.WarmCoolDecayLRSchedule'>: <function WarmCoolDecayLRSchedule.load at 0x7f2649a6b700>, <class 'speechbrain.processing.features.InputNormalization'>: <function InputNormalization._load at 0x7f264996f670>}\n",
      "checkpoint get_default_hook -----\n",
      "========================\n",
      " default_hooks : {<class 'torch.nn.modules.module.Module'>: <function torch_parameter_transfer at 0x7f26850f9940>, <class 'sentencepiece.SentencePieceProcessor'>: <function _load_spm at 0x7f26850f99d0>, <class 'speechbrain.processing.features.InputNormalization'>: <function InputNormalization._load at 0x7f264996f670>}\n",
      "checkpoint mro : (<class '__main__.ASR'>, <class 'speechbrain.core.Brain'>, <class 'object'>)\n",
      "checkpoint cls : <class '__main__.ASR'>\n",
      "checkpoint cls : <class 'speechbrain.core.Brain'>\n",
      "checkpoint cls : <class 'object'>\n",
      "default_hook 1 ----- : None\n",
      "checkpoint get_default_hook -----\n",
      "========================\n",
      " default_hooks : {<class 'torch.nn.modules.module.Module'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.optimizer.Optimizer'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.lr_scheduler._LRScheduler'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.cuda.amp.grad_scaler.GradScaler'>: <function torch_recovery at 0x7f26850f9820>, <class 'torch.optim.lr_scheduler.CyclicLR'>: <function _cycliclrloader at 0x7f24ebf8ee50>, <class 'speechbrain.dataio.encoder.CategoricalEncoder'>: <function CategoricalEncoder.load_if_possible at 0x7f2685103160>, <class 'speechbrain.dataio.dataloader.SaveableDataLoader'>: <function SaveableDataLoader._speechbrain_load at 0x7f265abc1dc0>, <class 'speechbrain.dataio.dataloader.LoopedLoader'>: <function LoopedLoader.load at 0x7f265ab70160>, <class 'speechbrain.utils.epoch_loop.EpochCounter'>: <function EpochCounter._recover at 0x7f265a7f68b0>, <class 'speechbrain.core.Brain'>: <function Brain._recover at 0x7f2649ac1b80>, <class 'speechbrain.nnet.schedulers.NewBobScheduler'>: <function NewBobScheduler.load at 0x7f2649a59ca0>, <class 'speechbrain.nnet.schedulers.LinearWarmupScheduler'>: <function LinearWarmupScheduler.load at 0x7f2649a690d0>, <class 'speechbrain.nnet.schedulers.NoamScheduler'>: <function NoamScheduler.load at 0x7f2649a695e0>, <class 'speechbrain.nnet.schedulers.CyclicCosineScheduler'>: <function CyclicCosineScheduler.load at 0x7f2649a698b0>, <class 'speechbrain.nnet.schedulers.ReduceLROnPlateau'>: <function ReduceLROnPlateau.load at 0x7f2649a69af0>, <class 'speechbrain.nnet.schedulers.CyclicLRScheduler'>: <function CyclicLRScheduler.load at 0x7f2649a69ee0>, <class 'speechbrain.nnet.schedulers.IntervalScheduler'>: <function IntervalScheduler.load at 0x7f2649a6b280>, <class 'speechbrain.nnet.schedulers.WarmCoolDecayLRSchedule'>: <function WarmCoolDecayLRSchedule.load at 0x7f2649a6b700>, <class 'speechbrain.processing.features.InputNormalization'>: <function InputNormalization._load at 0x7f264996f670>}\n",
      "checkpoint mro : (<class '__main__.ASR'>, <class 'speechbrain.core.Brain'>, <class 'object'>)\n",
      "checkpoint cls : <class '__main__.ASR'>\n",
      "checkpoint cls : <class 'speechbrain.core.Brain'>\n",
      "************************\n",
      "default_hooks[cls] : <function Brain._recover at 0x7f2649ac1b80>\n",
      "default_hook 2 ----- : <function Brain._recover at 0x7f2649ac1b80>\n",
      "--------- before default_hook -----\n",
      " loadpath : model_local/model.ckpt\n",
      " end_of_epoch : False\n",
      " device : None\n",
      "core _recover --------\n",
      "path : model_local/model.ckpt\n",
      "end_of_epoch : False\n",
      "device : None\n",
      "file opne -------\n",
      "path : model_local/model.ckpt\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1648293/3649872624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/speechbrain/speechbrain/utils/parameter_transfer.py\u001b[0m in \u001b[0;36mload_collected\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mparamfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_in\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'load_colleted paramfiles[name] : {paramfiles[name]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_load_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_load_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparamfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/speechbrain/speechbrain/utils/parameter_transfer.py\u001b[0m in \u001b[0;36m_call_load_hooks\u001b[0;34m(self, paramfiles, device)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' device : {device}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mdefault_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloadpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_of_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'--------- after default_hook -----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/speechbrain/speechbrain/core.py\u001b[0m in \u001b[0;36m_recover\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;31m# import chardet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;31m# print(chardet.detect(file_data.encode()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0msave_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'save_dict : {save_dict}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"step\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/yaml/__init__.py\u001b[0m in \u001b[0;36msafe_load\u001b[0;34m(stream)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msafe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muntrusted\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSafeLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_load_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/yaml/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(stream, Loader)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mproduce\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \"\"\"\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_single_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/yaml/loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mScanner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/yaml/reader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetermine_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/yaml/reader.py\u001b[0m in \u001b[0;36mdetermine_encoding\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetermine_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_buffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBOM_UTF16_LE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/yaml/reader.py\u001b[0m in \u001b[0;36mupdate_raw\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_buffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 64: invalid start byte"
     ]
    }
   ],
   "source": [
    "pretrain.load_collected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
